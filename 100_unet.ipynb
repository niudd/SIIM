{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataset_unet import prepare_trainset\n",
    "from utils import save_checkpoint, load_checkpoint, set_logger\n",
    "from gpu_utils import set_n_get_device\n",
    "\n",
    "from model.model_unet2 import UNetResNet34, predict_proba\n",
    "#from model.model_unet_classify_zero import UNetResNet34 as ZeroMaskClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Config the training process #########\n",
    "#device = set_n_get_device(\"0, 1, 2, 3\", data_device_id=\"cuda:0\")#0, 1, 2, 3, IMPORTANT: data_device_id is set to free gpu for storing the model, e.g.\"cuda:1\"\n",
    "MODEL = 'UNetResNet34'#'RESNET34', 'RESNET18', 'INCEPTION_V3', 'BNINCEPTION', 'SEResnet50'\n",
    "#AUX_LOGITS = True#False, only for 'INCEPTION_V3'\n",
    "print('====MODEL ACHITECTURE: %s===='%MODEL)\n",
    "\n",
    "device = set_n_get_device(\"0\", data_device_id=\"cuda:0\")#0, 1, 2, 3, IMPORTANT: data_device_id is set to free gpu for storing the model, e.g.\"cuda:1\"\n",
    "multi_gpu = None #[0, 1]#use 2 gpus\n",
    "\n",
    "SEED = 1234 #5678#4567#3456#2345#1234\n",
    "debug = True # if True, load 100 samples\n",
    "IMG_SIZE = 1024 #768\n",
    "BATCH_SIZE = 2\n",
    "NUM_WORKERS = 24\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl = prepare_trainset(BATCH_SIZE, NUM_WORKERS, SEED, IMG_SIZE, debug, nonempty_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, (images, masks) in enumerate(train_dl):\n",
    "    images = images.to(device=device, dtype=torch.float)\n",
    "    masks = masks.to(device=device, dtype=torch.float)\n",
    "    #labels = (torch.sum(masks.reshape(masks.size()[0], -1), dim=1, keepdim=True)==0).to(device=device, dtype=torch.float) #1 for non-zero-mask\n",
    "    if i==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.size(), masks.size()#, labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = UNetResNet34(debug=True).cuda(device=device)\n",
    "#net = ZeroMaskClassifier(debug=True).cuda(device=device)\n",
    "\n",
    "#torch.cuda.set_device(0)\n",
    "#torch.distributed.init_process_group(backend='nccl', world_size=4, init_method='...')\n",
    "#net = DistributedDataParallel(net, device_ids=[0], output_device=0)\n",
    "#torch.distributed.init_process_group(backend=\"nccl\")\n",
    "\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_512_v1_seed3456/best.pth.tar'\n",
    "#net, _ = load_checkpoint(checkpoint_path, net)\n",
    "\n",
    "#net = nn.DataParallel(net, device_ids=multi_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logit = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_FUNC = nn.BCEWithLogitsLoss()\n",
    "bce_loss = Loss_FUNC(logit, masks)\n",
    "bce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_loss = net.criterion(logit, masks)\n",
    "_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_metric = net.metric(logit, masks)\n",
    "_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# i = 1\n",
    "\n",
    "# fig = plt.figure(figsize=(8, 5))\n",
    "# if masks[i].mean()==0:\n",
    "#     plt.title('Empty mask')\n",
    "# else:\n",
    "#     plt.title('See marker')\n",
    "\n",
    "# ax = fig.add_subplot(1, 2, 1)\n",
    "# plt.imshow(image.cpu().numpy()[i][0], cmap=plt.cm.bone)\n",
    "# plt.imshow(masks.cpu().numpy()[i][0], alpha=0.3, cmap=\"Reds\")\n",
    "\n",
    "# ax = fig.add_subplot(1, 2, 2)\n",
    "# plt.imshow(image.cpu().numpy()[i][0], cmap=plt.cm.bone)\n",
    "# plt.imshow((logit>0).float().cpu().detach().numpy()[i][0], alpha=0.3, cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import save_checkpoint, load_checkpoint, set_logger\n",
    "from gpu_utils import set_n_get_device\n",
    "\n",
    "from dataset_unet import prepare_trainset\n",
    "#from model.model_unet import UNetResNet34, predict_proba\n",
    "from model.model_unet_classify_zero import UNetResNet34\n",
    "\n",
    "#from sync_batchnorm import convert_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Define the training process #########\n",
    "def run_check_net(train_dl, val_dl, multi_gpu=[0, 1]):\n",
    "    set_logger(LOG_PATH)\n",
    "    logging.info('\\n\\n')\n",
    "    #---\n",
    "    if MODEL == 'UNetResNet34':\n",
    "        net = UNetResNet34(debug=False).cuda(device=device)\n",
    "    #elif MODEL == 'RESNET18':\n",
    "    #    net = AtlasResNet18(debug=False).cuda(device=device)\n",
    "\n",
    "#     for param in net.named_parameters():\n",
    "#         if param[0][:8] in ['decoder5']:#'decoder5', 'decoder4', 'decoder3', 'decoder2'\n",
    "#             param[1].requires_grad = False\n",
    "\n",
    "    # dummy sgd to see if it can converge ...\n",
    "    optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, net.parameters()),\n",
    "                      lr=LearningRate, momentum=0.9, weight_decay=0.0001)\n",
    "    #optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=0.045)#LearningRate\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', \n",
    "                                                           factor=0.5, patience=4,#4 resnet34 \n",
    "                                                           verbose=False, threshold=0.0001, \n",
    "                                                           threshold_mode='rel', cooldown=0, \n",
    "                                                           min_lr=0, eps=1e-08)\n",
    "    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=0.9, last_epoch=-1)\n",
    "    \n",
    "    if warm_start:\n",
    "        logging.info('warm_start: '+last_checkpoint_path)\n",
    "        net, _ = load_checkpoint(last_checkpoint_path, net)\n",
    "    \n",
    "    # using multi GPU\n",
    "    if multi_gpu is not None:\n",
    "        net = nn.DataParallel(net, device_ids=multi_gpu)\n",
    "    \n",
    "    #use sync_batchnorm\n",
    "    #net = convert_model(net)\n",
    "\n",
    "    diff = 0\n",
    "    best_val_metric = -0.1\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #seed = get_seed()\n",
    "    #seed = SEED\n",
    "    #logging.info('aug seed: '+str(seed))\n",
    "    #ia.imgaug.seed(seed)\n",
    "    #np.random.seed(seed)\n",
    "    \n",
    "    for i_epoch in range(NUM_EPOCHS):\n",
    "        t0 = time.time()\n",
    "        # iterate through trainset\n",
    "        if multi_gpu is not None:\n",
    "            net.module.set_mode('train')\n",
    "        else:\n",
    "            net.set_mode('train')\n",
    "        train_loss_list, train_metric_list = [], []\n",
    "        #for seed in [1]:#[1, SEED]:#augment raw data with a duplicate one (augmented)\n",
    "        #seed = get_seed()\n",
    "        #np.random.seed(seed)\n",
    "        #ia.imgaug.seed(i//10)\n",
    "        for i, (image, masks) in enumerate(train_dl):\n",
    "            input_data = image.to(device=device, dtype=torch.float)\n",
    "            #1 for non-zero-mask\n",
    "            truth = (torch.sum(masks.reshape(masks.size()[0], -1), dim=1, keepdim=True)==0).to(device=device, dtype=torch.float)\n",
    "            #set_trace()\n",
    "            logit = net(input_data)#[:, :3, :, :]\n",
    "            \n",
    "            if multi_gpu is not None:\n",
    "                _train_loss = net.module.criterion(logit, truth)\n",
    "                _train_metric = net.module.metric(logit, truth)#device='gpu'\n",
    "            else:\n",
    "                _train_loss = net.criterion(logit, truth)\n",
    "                _train_metric = net.metric(logit, truth)#device='gpu'\n",
    "            train_loss_list.append(_train_loss.item())\n",
    "            train_metric_list.append(_train_metric.item())#.detach()\n",
    "\n",
    "            _train_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        train_loss = np.mean(train_loss_list)\n",
    "        train_metric = np.mean(train_metric_list)\n",
    "\n",
    "        # compute valid loss & metrics (concatenate valid set in cpu, then compute loss, metrics on full valid set)\n",
    "        net.module.set_mode('valid')\n",
    "        with torch.no_grad():\n",
    "#             val_loss_list, val_metric_list = [], []\n",
    "#             for i, (image, masks) in enumerate(val_dl):\n",
    "#                 input_data = image.to(device=device, dtype=torch.float)\n",
    "#                 truth = masks.to(device=device, dtype=torch.float)\n",
    "#                 logit = net(input_data)\n",
    "                \n",
    "#                 if multi_gpu is not None:\n",
    "#                     _val_loss  = net.module.criterion(logit, truth)\n",
    "#                     _val_metric  = net.module.metric(logit, truth)#device='gpu'\n",
    "#                 else:\n",
    "#                     _val_loss  = net.criterion(logit, truth)\n",
    "#                     _val_metric  = net.metric(logit, truth)#device='gpu'\n",
    "#                 val_loss_list.append(_val_loss.item())\n",
    "#                 val_metric_list.append(_val_metric.item())#.detach()\n",
    "\n",
    "#             val_loss = np.mean(val_loss_list)\n",
    "#             val_metric = np.mean(val_metric_list)\n",
    "            \n",
    "            logit_valid, truth_valid = None, None\n",
    "            for j, (image, masks) in enumerate(val_dl):\n",
    "                input_data = image.to(device=device, dtype=torch.float)\n",
    "                logit = net(input_data).cpu().float()\n",
    "                #1 for non-zero-mask\n",
    "                truth = (torch.sum(masks.reshape(masks.size()[0], -1), dim=1, keepdim=True)==0).cpu().float()\n",
    "                if logit_valid is None:\n",
    "                    logit_valid = logit\n",
    "                    truth_valid = truth\n",
    "                else:\n",
    "                    logit_valid = torch.cat((logit_valid, logit), dim=0)\n",
    "                    truth_valid = torch.cat((truth_valid, truth), dim=0)\n",
    "            if multi_gpu is not None:\n",
    "                val_loss = net.module.criterion(logit_valid, truth_valid)\n",
    "                val_metric = net.module.metric(logit_valid, truth_valid)\n",
    "            else:\n",
    "                val_loss = net.criterion(logit_valid, truth_valid)\n",
    "                val_metric = net.metric(logit_valid, truth_valid)\n",
    "\n",
    "        # Adjust learning_rate\n",
    "        scheduler.step(val_metric)\n",
    "        #\n",
    "        if val_metric > best_val_metric:\n",
    "            best_val_metric = val_metric\n",
    "            is_best = True\n",
    "            diff = 0\n",
    "        else:\n",
    "            is_best = False\n",
    "            diff += 1\n",
    "            if diff > early_stopping_round:\n",
    "                logging.info('Early Stopping: val_metric does not increase %d rounds'%early_stopping_round)\n",
    "                #print('Early Stopping: val_iou does not increase %d rounds'%early_stopping_round)\n",
    "                break\n",
    "        \n",
    "        #save checkpoint\n",
    "        checkpoint_dict = \\\n",
    "        {\n",
    "            'epoch': i,\n",
    "            'state_dict': net.module.state_dict() if multi_gpu is not None else net.state_dict(),\n",
    "            'optim_dict' : optimizer.state_dict(),\n",
    "            'metrics': {'train_loss': train_loss, 'val_loss': val_loss, \n",
    "                        'train_metric': train_metric, 'val_metric': val_metric}\n",
    "        }\n",
    "        save_checkpoint(checkpoint_dict, is_best=is_best, checkpoint=checkpoint_path)\n",
    "\n",
    "        #if i_epoch%20==0:\n",
    "        if i_epoch>-1:\n",
    "            logging.info('[EPOCH %05d]train_loss, train_metric: %0.5f, %0.5f; val_loss, val_metric: %0.5f, %0.5f; time elapsed: %0.1f min'%(i_epoch, train_loss.item(), train_metric.item(), val_loss.item(), val_metric.item(), (time.time()-t0)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #\n",
    "# def seed_everything(seed):\n",
    "#     random.seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "#     #tf.set_random_seed(seed)\n",
    "# seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Config the training process #########\n",
    "#device = set_n_get_device(\"0, 1, 2, 3\", data_device_id=\"cuda:0\")#0, 1, 2, 3, IMPORTANT: data_device_id is set to free gpu for storing the model, e.g.\"cuda:1\"\n",
    "MODEL = 'UNetResNet34'#'RESNET34', 'RESNET18', 'INCEPTION_V3', 'BNINCEPTION', 'SEResnet50'\n",
    "#AUX_LOGITS = True#False, only for 'INCEPTION_V3'\n",
    "print('====MODEL ACHITECTURE: %s===='%MODEL)\n",
    "\n",
    "device = set_n_get_device(\"0, 2\", data_device_id=\"cuda:0\")#0, 1, 2, 3, IMPORTANT: data_device_id is set to free gpu for storing the model, e.g.\"cuda:1\"\n",
    "multi_gpu = [0, 1]#use 2 gpus\n",
    "\n",
    "SEED = 1234#5678#4567#3456#2345#1234\n",
    "debug = True# if True, load 100 samples\n",
    "IMG_SIZE = 512#256\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 24\n",
    "warm_start, last_checkpoint_path = False, 'checkpoint/%s_%s_v1_seed%s/best.pth.tar'%(MODEL, IMG_SIZE, SEED)\n",
    "checkpoint_path = 'checkpoint/nonzero_stage1_%s_%s_v1_seed%s'%(MODEL, IMG_SIZE, SEED)\n",
    "LOG_PATH = 'logging/nonzero_stage1_%s_%s_v1_seed%s.log'%(MODEL, IMG_SIZE, SEED)#\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "early_stopping_round = 10#500#50\n",
    "LearningRate = 0.02#0.02#0.002\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######### Load data #########\n",
    "train_dl, val_dl = prepare_trainset(BATCH_SIZE, NUM_WORKERS, SEED, IMG_SIZE, debug)\n",
    "\n",
    "######### Run the training process #########\n",
    "run_check_net(train_dl, val_dl, multi_gpu=multi_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the validset, and analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move checkpoint from gamma machine to here\n",
    "cd checkpoint\n",
    "scp -r endi.niu@10.171.36.214:/home/endi.niu/SIIM/checkpoint/UNetResNet34_1024_v1_seed8901/ UNetResNet34_1024_v1_seed8901\n",
    "cd logging\n",
    "scp -r endi.niu@10.171.36.214:/home/endi.niu/SIIM/logging/UNetResNet34_1024_v1_seed8901.log UNetResNet34_1024_v1_seed8901.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pickle\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "import gc\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import save_checkpoint, load_checkpoint, set_logger\n",
    "from gpu_utils import set_n_get_device\n",
    "\n",
    "#from model.model_unet import UNetResNet34, predict_proba\n",
    "from model.model_unet2 import UNetResNet34, predict_proba\n",
    "from dataset_unet import prepare_trainset\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def inverse_sigmoid(x):\n",
    "    return np.log(x / (1-x))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====MODEL ACHITECTURE: UNetResNet34====\n"
     ]
    }
   ],
   "source": [
    "######### Config the training process #########\n",
    "#device = set_n_get_device(\"0, 1, 2, 3\", data_device_id=\"cuda:0\")#0, 1, 2, 3, IMPORTANT: data_device_id is set to free gpu for storing the model, e.g.\"cuda:1\"\n",
    "MODEL = 'UNetResNet34'#'RESNET34', 'RESNET18', 'INCEPTION_V3', 'BNINCEPTION', 'SEResnet50'\n",
    "#AUX_LOGITS = True#False, only for 'INCEPTION_V3'\n",
    "print('====MODEL ACHITECTURE: %s===='%MODEL)\n",
    "\n",
    "device = set_n_get_device(\"0,1\", data_device_id=\"cuda:0\")#0, 1, 2, 3, IMPORTANT: data_device_id is set to free gpu for storing the model, e.g.\"cuda:1\"\n",
    "multi_gpu = [0,1] #None#[0, 1]#use 2 gpus\n",
    "\n",
    "SEED = 1234 #5678#4567#3456#2345#1234\n",
    "debug = False # if True, load 100 samples\n",
    "IMG_SIZE = 1024 #768#512\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl = prepare_trainset(BATCH_SIZE, NUM_WORKERS, SEED, IMG_SIZE, debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y should be makeup\n",
    "y_valid = []\n",
    "for i, (image, masks) in enumerate(val_dl):\n",
    "    #if i==10:\n",
    "    #    break\n",
    "    truth = masks.to(device=device, dtype=torch.float)\n",
    "    y_valid.append(truth.cpu().numpy())\n",
    "y_valid = np.concatenate(y_valid, axis=0)\n",
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNetResNet34(debug=False).cuda(device=device)\n",
    "\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_512_v1_seed1234/best.pth.tar'\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_512_v1_seed2345/best.pth.tar'\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_512_v1_seed3456/best.pth.tar'\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_512_v1_seed4567/best.pth.tar'\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_512_v1_seed5678/best.pth.tar'\n",
    "\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_768_v1_seed3456/best.pth.tar'\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_768_v1_seed2345/best.pth.tar'\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_768_v1_seed1234/best.pth.tar'\n",
    "\n",
    "checkpoint_path = 'checkpoint/UNetResNet34_1024_v1_seed1234/best.pth.tar'\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_1024_v1_seed2345/best.pth.tar'\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_1024_v1_seed3456/best.pth.tar'\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_1024_v1_seed4567/best.pth.tar'\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_1024_v1_seed5678/best.pth.tar'\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_1024_v1_seed6789/best.pth.tar'\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_1024_v1_seed7890/best.pth.tar'\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_1024_v1_seed8901/best.pth.tar'\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_1024_v1_seed9012/best.pth.tar'\n",
    "\n",
    "net, _ = load_checkpoint(checkpoint_path, net)\n",
    "if multi_gpu is not None:\n",
    "    net = nn.DataParallel(net, device_ids=multi_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "preds_valid = predict_proba(net, val_dl, device, multi_gpu=multi_gpu, mode='valid', tta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid.shape, preds_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('prediction/UNetResNet34_512_v1_seed5678__preds_valid.pkl', 'wb') as f:\n",
    "#     pickle.dump(preds_valid, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ensemble logits\n",
    "# with open('prediction/UNetResNet34_512_v1_seed1234__preds_valid.pkl', 'rb') as f:\n",
    "#     preds_valid_1234 = pickle.load(f)\n",
    "# with open('prediction/UNetResNet34_512_v1_seed2345__preds_valid.pkl', 'rb') as f:\n",
    "#     preds_valid_2345 = pickle.load(f)\n",
    "# with open('prediction/UNetResNet34_512_v1_seed3456__preds_valid.pkl', 'rb') as f:\n",
    "#     preds_valid_3456 = pickle.load(f)\n",
    "# with open('prediction/UNetResNet34_512_v1_seed4567__preds_valid.pkl', 'rb') as f:\n",
    "#     preds_valid_4567 = pickle.load(f)\n",
    "# with open('prediction/UNetResNet34_512_v1_seed5678__preds_valid.pkl', 'rb') as f:\n",
    "#     preds_valid_5678 = pickle.load(f)\n",
    "\n",
    "# preds_valid = inverse_sigmoid((sigmoid(preds_valid_1234) + sigmoid(preds_valid_2345) + sigmoid(preds_valid_3456) + \\\n",
    "#                sigmoid(preds_valid_4567) + sigmoid(preds_valid_5678)) / 5)\n",
    "\n",
    "# del preds_valid_1234, preds_valid_2345, preds_valid_3456, preds_valid_4567, preds_valid_5678\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## search for best thresholds\n",
    "def calculate_dice(logit, truth, EMPTY_THRESHOLD=400, MASK_THRESHOLD=0.22):\n",
    "    IMG_SIZE = logit.shape[-1] #256\n",
    "    logit = sigmoid(logit)#.reshape(n, -1)\n",
    "    pred = (logit>MASK_THRESHOLD).astype(np.int)\n",
    "    pred_clf = (pred.reshape(pred.shape[0], -1).sum(axis=1)<EMPTY_THRESHOLD).astype(np.int)\n",
    "    pred[pred_clf.reshape(-1,)==1, ] = 0\n",
    "    return dice_overall(pred, truth)\n",
    "\n",
    "def dice_overall(pred_mask, truth_mask, eps=1e-8):\n",
    "    n = pred_mask.shape[0]\n",
    "    pred_mask = pred_mask.reshape(n, -1)\n",
    "    truth_mask = truth_mask.reshape(n, -1)\n",
    "    intersect = (pred_mask * truth_mask).sum(axis=1).astype(np.float)\n",
    "    union = (pred_mask + truth_mask).sum(axis=1).astype(np.float)\n",
    "    return ((2.0*intersect + eps) / (union+eps)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#np.arange(1400, 1520, 20) for 512#np.arange(350, 450, 10) for 256\n",
    "EMPTY_THRESHOLD_candidate = np.arange(6000, 7000, 100) #for 1024\n",
    "#EMPTY_THRESHOLD_candidate = np.arange(2900, 3300, 100)#np.arange(2900, 4200, 100)#for 768\n",
    "MASK_THRESHOLD_candidate = np.arange(0.18, 0.23, 0.01)#np.arange(0.19, 0.27, 0.01)\n",
    "M, N = len(EMPTY_THRESHOLD_candidate), len(MASK_THRESHOLD_candidate)\n",
    "best_threshold = None\n",
    "best_score = 0\n",
    "\n",
    "for i in tqdm_notebook(range(M)):\n",
    "    EMPTY_THRESHOLD = EMPTY_THRESHOLD_candidate[i]\n",
    "    for j in range(N):\n",
    "        MASK_THRESHOLD = MASK_THRESHOLD_candidate[j]\n",
    "        dice_score = calculate_dice(preds_valid, y_valid.squeeze(1), EMPTY_THRESHOLD, MASK_THRESHOLD)\n",
    "        print('CLF_EMPTY_THRESHOLD: %f, MASK_THRESHOLD: %f, dice_score: %f'%(EMPTY_THRESHOLD, MASK_THRESHOLD, dice_score))\n",
    "        if dice_score>best_score:\n",
    "            best_threshold = [EMPTY_THRESHOLD, MASK_THRESHOLD]\n",
    "            best_score = dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5300, 0.22, -1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SEED=1234, 1440, 0.19, 0.8279538590003902 #1460, 0.22, 0.8287955663678874\n",
    "#SEED=2345, 1460, 0.23, 0.8463693358025216\n",
    "#SEED=3456, 1440, 0.24, 0.8369784053672372\n",
    "#SEED=4567, 1460, 0.23, 0.8343691236465608\n",
    "#SEED=5678, 1480, 0.19, 0.8402239554128049\n",
    "\n",
    "#ensemble 5 seeds, 1420, 0.2, 0.8869549480310523\n",
    "\n",
    "#EMPTY_THRESHOLD, MASK_THRESHOLD = best_threshold\n",
    "EMPTY_THRESHOLD, MASK_THRESHOLD, best_score = 5300, 0.22, -1\n",
    "EMPTY_THRESHOLD, MASK_THRESHOLD, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mask(logit, EMPTY_THRESHOLD, MASK_THRESHOLD):\n",
    "    \"\"\"Transform each prediction into mask.\n",
    "    input shape: (256, 256)\n",
    "    \"\"\"\n",
    "    #pred mask 0-1 pixel-wise\n",
    "    #n = logit.shape[0]\n",
    "    IMG_SIZE = logit.shape[-1] #256\n",
    "    #EMPTY_THRESHOLD = 100.0*(IMG_SIZE/128.0)**2 #count of predicted mask pixles<threshold, predict as empty mask image\n",
    "    #MASK_THRESHOLD = 0.22\n",
    "    #logit = torch.sigmoid(torch.from_numpy(logit)).view(n, -1)\n",
    "    #pred = (logit>MASK_THRESHOLD).long()\n",
    "    #pred[pred.sum(dim=1) < EMPTY_THRESHOLD, ] = 0 #bug here, found it, the bug is input shape is (256, 256) not (16,256,256)\n",
    "    logit = sigmoid(logit)#.reshape(n, -1)\n",
    "    pred = (logit>MASK_THRESHOLD).astype(np.int)\n",
    "    if pred.sum() < EMPTY_THRESHOLD:\n",
    "        return np.zeros(pred.shape).astype(np.int)\n",
    "    else:\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## visualize predicted masks\n",
    "start = 0\n",
    "rows = 10\n",
    "\n",
    "cnt = 0\n",
    "for idx, (img, mask) in enumerate(val_dl):\n",
    "    if idx<start:\n",
    "        continue\n",
    "    for j in range(BATCH_SIZE):#BATCH_SIZE=8\n",
    "        not_empty = mask[j][0].sum()>0\n",
    "        if not_empty:\n",
    "            cnt+=1\n",
    "            pred_mask = predict_mask(preds_valid[idx*BATCH_SIZE+j], EMPTY_THRESHOLD, MASK_THRESHOLD)#EMPTY_THRESHOLD=0\n",
    "            #if pred_mask.sum()==0:\n",
    "            #    continue\n",
    "            fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(12, 4))\n",
    "            ax0.imshow(img[j][0].numpy(), plt.cm.bone)\n",
    "            ax1.imshow(mask[j][0], vmin=0, vmax=1, cmap=\"Reds\")\n",
    "            ax2.imshow(pred_mask, vmin=0, vmax=1, cmap=\"Blues\")\n",
    "            if not_empty.item():\n",
    "                ax1.set_title('Targets(Has Mask)')\n",
    "            else:\n",
    "                ax1.set_title('Targets(Empty)')\n",
    "            ax2.set_title('Predictions')\n",
    "        if cnt>rows:\n",
    "            break\n",
    "    if cnt>rows:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from dataset_unet import prepare_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1377, '1.2.276.0.7230010.3.1.4.8323329.6160.1517875196.806852')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fnames = [f.split('/')[-1][:-4] for f in glob.glob('data/processed/test/*')]\n",
    "len(test_fnames), test_fnames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = prepare_testset(BATCH_SIZE, NUM_WORKERS, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use TTA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/data/endi/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/bigdata/data/endi/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30min 58s, sys: 13min, total: 43min 59s\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds_test = predict_proba(net, test_dl, device, multi_gpu=multi_gpu, mode='test', tta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ##for ensemble\n",
    "# net = UNetResNet34(debug=False).cuda(device=device)\n",
    "# checkpoint_path = 'checkpoint/UNetResNet34_512_v1_seed1234/best.pth.tar'\n",
    "# net, _ = load_checkpoint(checkpoint_path, net)\n",
    "# preds_test_1234 = predict_proba(net, test_dl, device, multi_gpu=False, mode='test', tta=True)\n",
    "# print('seed1234 complete')\n",
    "\n",
    "# net = UNetResNet34(debug=False).cuda(device=device)\n",
    "# checkpoint_path = 'checkpoint/UNetResNet34_512_v1_seed2345/best.pth.tar'\n",
    "# net, _ = load_checkpoint(checkpoint_path, net)\n",
    "# preds_test_2345 = predict_proba(net, test_dl, device, multi_gpu=False, mode='test', tta=True)\n",
    "# print('seed2345 complete')\n",
    "\n",
    "# net = UNetResNet34(debug=False).cuda(device=device)\n",
    "# checkpoint_path = 'checkpoint/UNetResNet34_512_v1_seed3456/best.pth.tar'\n",
    "# net, _ = load_checkpoint(checkpoint_path, net)\n",
    "# preds_test_3456 = predict_proba(net, test_dl, device, multi_gpu=False, mode='test', tta=True)\n",
    "# print('seed3456 complete')\n",
    "\n",
    "# net = UNetResNet34(debug=False).cuda(device=device)\n",
    "# checkpoint_path = 'checkpoint/UNetResNet34_512_v1_seed4567/best.pth.tar'\n",
    "# net, _ = load_checkpoint(checkpoint_path, net)\n",
    "# preds_test_4567 = predict_proba(net, test_dl, device, multi_gpu=False, mode='test', tta=True)\n",
    "# print('seed4567 complete')\n",
    "\n",
    "# net = UNetResNet34(debug=False).cuda(device=device)\n",
    "# checkpoint_path = 'checkpoint/UNetResNet34_512_v1_seed5678/best.pth.tar'\n",
    "# net, _ = load_checkpoint(checkpoint_path, net)\n",
    "# preds_test_5678 = predict_proba(net, test_dl, device, multi_gpu=False, mode='test', tta=True)\n",
    "# print('seed5678 complete')\n",
    "\n",
    "# with open('prediction/UNetResNet34_512_v1__preds_test.pkl', 'wb') as f:\n",
    "#     pickle.dump([preds_test_1234, preds_test_2345, preds_test_3456, preds_test_4567, preds_test_5678], \n",
    "#                 f)\n",
    "\n",
    "# preds_test = inverse_sigmoid((sigmoid(preds_test_1234) + sigmoid(preds_test_2345) + sigmoid(preds_test_3456) + \\\n",
    "#                sigmoid(preds_test_4567) + sigmoid(preds_test_5678)) / 5)\n",
    "\n",
    "# del preds_test_1234, preds_test_2345, preds_test_3456, preds_test_4567, preds_test_5678\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1377, 1024, 1024)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## visualize predicted masks\n",
    "start = 0\n",
    "total = 19\n",
    "\n",
    "fig=plt.figure(figsize=(15, 20))\n",
    "cnt = 0\n",
    "for idx, img in enumerate(test_dl):\n",
    "    if idx<start:\n",
    "        continue\n",
    "    for j in range(BATCH_SIZE):#BATCH_SIZE=8\n",
    "        cnt+=1\n",
    "        pred_mask = predict_mask(preds_test[idx*BATCH_SIZE+j], EMPTY_THRESHOLD, MASK_THRESHOLD)\n",
    "        #if pred_mask.float().mean()==0:\n",
    "        #    continue\n",
    "        ax = fig.add_subplot(5, 4, cnt)\n",
    "        plt.imshow(img[j][0].numpy(), plt.cm.bone)\n",
    "        plt.imshow(pred_mask, alpha=0.3, cmap=\"Reds\")\n",
    "        if pred_mask.sum()>0:\n",
    "            plt.title('Predict Mask')\n",
    "        else:\n",
    "            plt.title('Predict Empty')\n",
    "        if cnt>total:\n",
    "            break\n",
    "    if cnt>total:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from mask_functions import mask2rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b106cfa5278749058e260ca2e8a79106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1377), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1377\n",
      "CPU times: user 17min 5s, sys: 1min, total: 18min 5s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#### Step 1: Generate rle encodings (images are first converted to the original size)\n",
    "rles = []\n",
    "for p in tqdm_notebook(preds_test):#p is logit from model\n",
    "    pred_mask = predict_mask(p, EMPTY_THRESHOLD, MASK_THRESHOLD)\n",
    "    if pred_mask.sum()>0:#predicted non-empty mask\n",
    "        im = PIL.Image.fromarray((pred_mask.T*255).astype(np.uint8)).resize((1024,1024))\n",
    "        im = np.asarray(im)\n",
    "        rles.append(mask2rle(im, 1024, 1024))\n",
    "    else: rles.append('-1')\n",
    "    \n",
    "sub_df = pd.DataFrame({'ImageId': test_fnames, 'EncodedPixels': rles})\n",
    "print(len(sub_df.index))\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6160.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.582.1517875163...</td>\n",
       "      <td>637106 2 1022 3 1017 1 3 3 1016 12 1011 15 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6985.151787520...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.5865.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6187.151787519...</td>\n",
       "      <td>256269 3 1021 3 1021 5 1018 7 1016 8 1013 8 10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ImageId  \\\n",
       "0  1.2.276.0.7230010.3.1.4.8323329.6160.151787519...   \n",
       "1  1.2.276.0.7230010.3.1.4.8323329.582.1517875163...   \n",
       "2  1.2.276.0.7230010.3.1.4.8323329.6985.151787520...   \n",
       "3  1.2.276.0.7230010.3.1.4.8323329.5865.151787519...   \n",
       "4  1.2.276.0.7230010.3.1.4.8323329.6187.151787519...   \n",
       "\n",
       "                                       EncodedPixels  \n",
       "0                                                 -1  \n",
       "1  637106 2 1022 3 1017 1 3 3 1016 12 1011 15 100...  \n",
       "2                                                 -1  \n",
       "3                                                 -1  \n",
       "4  256269 3 1021 3 1021 5 1018 7 1016 8 1013 8 10...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the correctness of transformation\n",
    "pred_mask = predict_mask(preds_test[22], EMPTY_THRESHOLD, MASK_THRESHOLD)\n",
    "im = PIL.Image.fromarray((pred_mask.T*255).astype(np.uint8)).resize((1024,1024))\n",
    "im = np.asarray(im)\n",
    "im.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc0c05a3ac8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission/0826_unet_1024_seed9012_tta_v1_6200_020.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sub_df.EncodedPixels!='-1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Step 2: the sub is Instance Segmentation, so need to split mask into instances of masks\n",
    "def split_mask(mask):\n",
    "    MASK_THRESHOLD = 0.2#0.22\n",
    "    EMPTY_THRESHOLD = 100#30 for IMG_SIZE=256 #ignore predictions composed of 30 pixels or less. This is tunable!!!\n",
    "    #split disconnected masks with ndimage.label function\n",
    "    labled,n_objs = ndimage.label(mask > MASK_THRESHOLD)\n",
    "    result = []\n",
    "    n_pixels = []\n",
    "    for i in range(n_objs):\n",
    "        obj = (labled == i + 1).astype(int)\n",
    "        if obj.sum() > EMPTY_THRESHOLD:\n",
    "            result.append(obj)\n",
    "            n_pixels.append(obj.sum())\n",
    "    #sort masks based on the number of pixels\n",
    "    result = [x for _,x in sorted(zip(n_pixels,result),reverse=True,key=lambda x:x[0])]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rles = []\n",
    "ids_c = []\n",
    "for p,idx in tqdm_notebook(zip(preds_test, test_fnames), total=len(preds_test)):\n",
    "    pred_mask = predict_mask(p, EMPTY_THRESHOLD, MASK_THRESHOLD)\n",
    "    if pred_mask.sum() > 0:\n",
    "        masks = split_mask(pred_mask)#to_np\n",
    "        for mask in masks:\n",
    "            ids_c.append(idx)\n",
    "            im = PIL.Image.fromarray((mask.T*255).astype(np.uint8)).resize((1024,1024))\n",
    "            im = np.asarray(im)\n",
    "            rles.append(mask2rle(im, 1024, 1024))\n",
    "        if len(masks) == 0:\n",
    "            rles.append('-1')\n",
    "            ids_c.append(idx)\n",
    "    else: \n",
    "        rles.append('-1')\n",
    "        ids_c.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({'ImageId': ids_c, 'EncodedPixels': rles})\n",
    "print(len(sub_df))\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission/0712_unet_512_seed1234_split.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
