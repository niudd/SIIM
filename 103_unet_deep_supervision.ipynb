{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataset_unet import prepare_trainset\n",
    "from utils import save_checkpoint, load_checkpoint, set_logger\n",
    "from gpu_utils import set_n_get_device\n",
    "\n",
    "#from model.model_unet_deep_supervision import UNetResNet34, predict_proba\n",
    "from model.deep_supervision_models_kaggler.unet import UNet as UNetResNet34\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====MODEL ACHITECTURE: UNetResNet34====\n"
     ]
    }
   ],
   "source": [
    "######### Config the training process #########\n",
    "#device = set_n_get_device(\"0, 1, 2, 3\", data_device_id=\"cuda:0\")#0, 1, 2, 3, IMPORTANT: data_device_id is set to free gpu for storing the model, e.g.\"cuda:1\"\n",
    "MODEL = 'UNetResNet34'#'RESNET34', 'RESNET18', 'INCEPTION_V3', 'BNINCEPTION', 'SEResnet50'\n",
    "#AUX_LOGITS = True#False, only for 'INCEPTION_V3'\n",
    "print('====MODEL ACHITECTURE: %s===='%MODEL)\n",
    "\n",
    "device = set_n_get_device(\"0\", data_device_id=\"cuda:0\")#0, 1, 2, 3, IMPORTANT: data_device_id is set to free gpu for storing the model, e.g.\"cuda:1\"\n",
    "multi_gpu = None#[0, 1]#use 2 gpus\n",
    "\n",
    "SEED = 1234#5678#4567#3456#2345#1234\n",
    "debug = True# if True, load 100 samples\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 24\n",
    "warm_start, last_checkpoint_path = False, 'checkpoint/%s_%s_v1_seed%s/best.pth.tar'%(MODEL, IMG_SIZE, SEED)\n",
    "checkpoint_path = 'checkpoint/deep_supervision_%s_%s_v2_seed%s'%(MODEL, IMG_SIZE, SEED)\n",
    "LOG_PATH = 'logging/deep_supervision_%s_%s_v2_seed%s.log'%(MODEL, IMG_SIZE, SEED)#\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "early_stopping_round = 10#500#50\n",
    "LearningRate = 0.02#phase1: 0.02, phase2: 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of trainset (for training):  900\n",
      "Count of validset (for training):  100\n"
     ]
    }
   ],
   "source": [
    "train_dl, val_dl = prepare_trainset(BATCH_SIZE, NUM_WORKERS, SEED, IMG_SIZE, debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, (images, masks) in enumerate(train_dl):\n",
    "    images = images.to(device=device, dtype=torch.float)\n",
    "    masks = masks.to(device=device, dtype=torch.float)\n",
    "    if i==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1, 512, 512]), torch.Size([4, 1, 512, 512]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.size(), masks.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define non-empty-mask as 1\n",
    "truth_clf = (masks.sum(dim=2).sum(dim=2)!=0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_clf.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/data/endi/SIIM-ACR Pneumothorax Segmentation/model/deep_supervision_models_kaggler/oc_net.py:45: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(self.W.weight, 0)\n",
      "/home/bigdata/data/endi/SIIM-ACR Pneumothorax Segmentation/model/deep_supervision_models_kaggler/oc_net.py:46: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(self.W.bias, 0)\n"
     ]
    }
   ],
   "source": [
    "#net = UNetResNet34(debug=True).cuda(device=device)\n",
    "\n",
    "net = UNetResNet34(basenet='resnet34', num_filters=16, pretrained='imagenet', debug=True).cuda(device=device)\n",
    "\n",
    "#torch.cuda.set_device(0)\n",
    "#torch.distributed.init_process_group(backend='nccl', world_size=4, init_method='...')\n",
    "#net = DistributedDataParallel(net, device_ids=[0], output_device=0)\n",
    "#torch.distributed.init_process_group(backend=\"nccl\")\n",
    "\n",
    "if multi_gpu is not None:\n",
    "    net = nn.DataParallel(net, device_ids=multi_gpu)\n",
    "\n",
    "#checkpoint_path = 'checkpoint/UNetResNet34_256_v1_seed1234/best.pth.tar'\n",
    "#net, _ = load_checkpoint(checkpoint_path, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  torch.Size([4, 3, 512, 512])\n",
      "e1 torch.Size([4, 64, 256, 256])\n",
      "e2 torch.Size([4, 64, 256, 256])\n",
      "e3 torch.Size([4, 128, 128, 128])\n",
      "e4 torch.Size([4, 256, 64, 64])\n",
      "e5 torch.Size([4, 512, 32, 32])\n",
      "c torch.Size([4, 128, 16, 16])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 1. Got 32 and 16 in dimension 2 at /pytorch/aten/src/THC/generic/THCTensorMath.cu:71",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-af9b150065ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogit_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data/endi/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/endi/SIIM-ACR Pneumothorax Segmentation/model/deep_supervision_models_kaggler/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0md5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'd5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/endi/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/endi/SIIM-ACR Pneumothorax Segmentation/model/deep_supervision_models_kaggler/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 1. Got 32 and 16 in dimension 2 at /pytorch/aten/src/THC/generic/THCTensorMath.cu:71"
     ]
    }
   ],
   "source": [
    "logit, logit_mask, logit_clf = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 1, 512, 512]),\n",
       " torch.Size([4, 1]),\n",
       " 5,\n",
       " torch.Size([4, 1, 512, 512]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.size(), logit_clf.size(), len(logit_mask), logit_mask[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8452, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = net.criterion(logit, logit_mask, logit_clf, masks, truth_clf)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002, device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_metric = net.metric(logit, masks)\n",
    "_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# i = 1\n",
    "\n",
    "# fig = plt.figure(figsize=(8, 5))\n",
    "# if masks[i].mean()==0:\n",
    "#     plt.title('Empty mask')\n",
    "# else:\n",
    "#     plt.title('See marker')\n",
    "\n",
    "# ax = fig.add_subplot(1, 2, 1)\n",
    "# plt.imshow(image.cpu().numpy()[i][0], cmap=plt.cm.bone)\n",
    "# plt.imshow(masks.cpu().numpy()[i][0], alpha=0.3, cmap=\"Reds\")\n",
    "\n",
    "# ax = fig.add_subplot(1, 2, 2)\n",
    "# plt.imshow(image.cpu().numpy()[i][0], cmap=plt.cm.bone)\n",
    "# plt.imshow((logit>0).float().cpu().detach().numpy()[i][0], alpha=0.3, cmap=\"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import save_checkpoint, load_checkpoint, set_logger\n",
    "from gpu_utils import set_n_get_device\n",
    "\n",
    "from dataset_unet import prepare_trainset\n",
    "from model.model_unet_multitask import UNetResNet34, predict_proba\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Define the training process #########\n",
    "def run_check_net(train_dl, val_dl, multi_gpu=[0, 1]):\n",
    "    set_logger(LOG_PATH)\n",
    "    logging.info('\\n\\n')\n",
    "    #---\n",
    "    if MODEL == 'UNetResNet34':\n",
    "        net = UNetResNet34(debug=False).cuda(device=device)\n",
    "    #elif MODEL == 'RESNET18':\n",
    "    #    net = AtlasResNet18(debug=False).cuda(device=device)\n",
    "\n",
    "#     for param in net.named_parameters():\n",
    "#         if param[0][:8] in ['decoder5']:#'decoder5', 'decoder4', 'decoder3', 'decoder2'\n",
    "#             param[1].requires_grad = False\n",
    "\n",
    "    # dummy sgd to see if it can converge ...\n",
    "    optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, net.parameters()),\n",
    "                      lr=LearningRate, momentum=0.9, weight_decay=0.0001)\n",
    "    #optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=0.045)#LearningRate\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', \n",
    "                                                           factor=0.5, patience=4,#4 resnet34 \n",
    "                                                           verbose=False, threshold=0.0001, \n",
    "                                                           threshold_mode='rel', cooldown=0, \n",
    "                                                           min_lr=0, eps=1e-08)\n",
    "    #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=0.9, last_epoch=-1)\n",
    "    \n",
    "    if warm_start:\n",
    "        logging.info('warm_start: '+last_checkpoint_path)\n",
    "        net, _ = load_checkpoint(last_checkpoint_path, net)\n",
    "    \n",
    "    # using multi GPU\n",
    "    if multi_gpu is not None:\n",
    "        net = nn.DataParallel(net, device_ids=multi_gpu)\n",
    "\n",
    "    diff = 0\n",
    "    best_val_metric = -0.1\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #seed = get_seed()\n",
    "    #seed = SEED\n",
    "    #logging.info('aug seed: '+str(seed))\n",
    "    #ia.imgaug.seed(seed)\n",
    "    #np.random.seed(seed)\n",
    "    \n",
    "    for i_epoch in range(NUM_EPOCHS):\n",
    "        t0 = time.time()\n",
    "        # iterate through trainset\n",
    "        if multi_gpu is not None:\n",
    "            net.module.set_mode('train')\n",
    "        else:\n",
    "            net.set_mode('train')\n",
    "        train_loss_list = []\n",
    "        train_loss_mask_list = []\n",
    "        train_loss_clf_list = []\n",
    "        train_metric_list = []\n",
    "        #for seed in [1]:#[1, SEED]:#augment raw data with a duplicate one (augmented)\n",
    "        #seed = get_seed()\n",
    "        #np.random.seed(seed)\n",
    "        #ia.imgaug.seed(i//10)\n",
    "        for i, (image, masks) in enumerate(train_dl):\n",
    "            input_data = image.to(device=device, dtype=torch.float)\n",
    "            truth_mask = masks.to(device=device, dtype=torch.float)\n",
    "            #define non-empty-mask as 1\n",
    "            truth_clf = (truth_mask.sum(dim=2).sum(dim=2)!=0).float()\n",
    "            #set_trace()\n",
    "            logit_mask, logit_clf = net(input_data)#[:, :3, :, :]\n",
    "            \n",
    "            if multi_gpu is not None:\n",
    "                _train_loss, _train_loss_mask, _train_loss_clf = net.module.criterion(logit_mask, truth_mask, logit_clf, truth_clf)\n",
    "                _train_metric = net.module.metric(logit_mask, truth_mask)#device='gpu'\n",
    "            else:\n",
    "                _train_loss, _train_loss_mask, _train_loss_clf = net.criterion(logit_mask, truth_mask, logit_clf, truth_clf)\n",
    "                _train_metric  = net.metric(logit_mask, truth_mask)#device='gpu'\n",
    "            train_loss_list.append(_train_loss.item())\n",
    "            train_loss_mask_list.append(_train_loss_mask.item())\n",
    "            train_loss_clf_list.append(_train_loss_clf.item())\n",
    "            train_metric_list.append(_train_metric.item())#.detach()\n",
    "\n",
    "            #grandient accumulation step=2\n",
    "            acc_step = 2\n",
    "            _train_loss = _train_loss / acc_step\n",
    "            _train_loss.backward()\n",
    "            if (i+1)%acc_step==0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        train_loss = np.mean(train_loss_list)\n",
    "        train_loss_mask = np.mean(train_loss_mask_list)\n",
    "        train_loss_clf = np.mean(train_loss_clf_list)\n",
    "        train_metric = np.mean(train_metric_list)\n",
    "\n",
    "        # compute valid loss & metrics (concatenate valid set in cpu, then compute loss, metrics on full valid set)\n",
    "        net.module.set_mode('valid')\n",
    "        with torch.no_grad():\n",
    "#             val_loss_list, val_metric_list = [], []\n",
    "#             for i, (image, masks) in enumerate(val_dl):\n",
    "#                 input_data = image.to(device=device, dtype=torch.float)\n",
    "#                 truth = masks.to(device=device, dtype=torch.float)\n",
    "#                 logit = net(input_data)\n",
    "                \n",
    "#                 if multi_gpu is not None:\n",
    "#                     _val_loss  = net.module.criterion(logit, truth)\n",
    "#                     _val_metric  = net.module.metric(logit, truth)#device='gpu'\n",
    "#                 else:\n",
    "#                     _val_loss  = net.criterion(logit, truth)\n",
    "#                     _val_metric  = net.metric(logit, truth)#device='gpu'\n",
    "#                 val_loss_list.append(_val_loss.item())\n",
    "#                 val_metric_list.append(_val_metric.item())#.detach()\n",
    "\n",
    "#             val_loss = np.mean(val_loss_list)\n",
    "#             val_metric = np.mean(val_metric_list)\n",
    "            \n",
    "            logit_mask_valid, logit_clf_valid, truth_mask_valid, truth_clf_valid = None, None, None, None\n",
    "            for j, (image, masks) in enumerate(val_dl):\n",
    "                input_data = image.to(device=device, dtype=torch.float)\n",
    "                truth_mask = masks.cpu().float()\n",
    "                #define non-empty-mask as 1\n",
    "                truth_clf = (truth_mask.sum(dim=2).sum(dim=2)!=0).cpu().float()\n",
    "                logit_mask, logit_clf = net(input_data)\n",
    "                logit_mask, logit_clf = logit_mask.cpu().float(), logit_clf.cpu().float()\n",
    "                if logit_mask_valid is None:\n",
    "                    logit_mask_valid = logit_mask\n",
    "                    logit_clf_valid = logit_clf\n",
    "                    truth_mask_valid = truth_mask\n",
    "                    truth_clf_valid = truth_clf\n",
    "                else:\n",
    "                    logit_mask_valid = torch.cat((logit_mask_valid, logit_mask), dim=0)\n",
    "                    logit_clf_valid = torch.cat((logit_clf_valid, logit_clf), dim=0)\n",
    "                    truth_mask_valid = torch.cat((truth_mask_valid, truth_mask), dim=0)\n",
    "                    truth_clf_valid = torch.cat((truth_clf_valid, truth_clf), dim=0)\n",
    "            if multi_gpu is not None:\n",
    "                val_loss, val_loss_mask, val_loss_clf = net.module.criterion(logit_mask_valid, truth_mask_valid, logit_clf_valid, truth_clf_valid)\n",
    "                val_metric = net.module.metric(logit_mask_valid, truth_mask_valid)\n",
    "            else:\n",
    "                val_loss, val_loss_mask, val_loss_clf = net.criterion(logit_mask_valid, truth_mask_valid, logit_clf_valid, truth_clf_valid)\n",
    "                val_metric = net.metric(logit_mask_valid, truth_mask_valid)\n",
    "\n",
    "        # Adjust learning_rate\n",
    "        scheduler.step(val_metric)\n",
    "        #\n",
    "        if val_metric > best_val_metric:\n",
    "            best_val_metric = val_metric\n",
    "            is_best = True\n",
    "            diff = 0\n",
    "        else:\n",
    "            is_best = False\n",
    "            diff += 1\n",
    "            if diff > early_stopping_round:\n",
    "                logging.info('Early Stopping: val_metric does not increase %d rounds'%early_stopping_round)\n",
    "                #print('Early Stopping: val_iou does not increase %d rounds'%early_stopping_round)\n",
    "                break\n",
    "        \n",
    "        #save checkpoint\n",
    "        checkpoint_dict = \\\n",
    "        {\n",
    "            'epoch': i,\n",
    "            'state_dict': net.module.state_dict() if multi_gpu is not None else net.state_dict(),\n",
    "            'optim_dict' : optimizer.state_dict(),\n",
    "            'metrics': {'train_loss': train_loss, 'val_loss': val_loss, \n",
    "                        'train_metric': train_metric, 'val_metric': val_metric}\n",
    "        }\n",
    "        save_checkpoint(checkpoint_dict, is_best=is_best, checkpoint=checkpoint_path)\n",
    "\n",
    "        #if i_epoch%20==0:\n",
    "        if i_epoch>-1:\n",
    "            logging.info('[EPOCH %05d]train_loss_mask, train_loss_clf, train_metric: %0.5f, %0.5f, %0.5f; val_loss_mask, val_loss_clf, val_metric: %0.5f, %0.5f, %0.5f; time elapsed: %0.1f min'%(i_epoch, train_loss_mask.item(), train_loss_clf.item(), train_metric.item(), val_loss_mask.item(), val_loss_clf.item(), val_metric.item(), (time.time()-t0)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====MODEL ACHITECTURE: UNetResNet34====\n"
     ]
    }
   ],
   "source": [
    "######### Config the training process #########\n",
    "#device = set_n_get_device(\"0, 1, 2, 3\", data_device_id=\"cuda:0\")#0, 1, 2, 3, IMPORTANT: data_device_id is set to free gpu for storing the model, e.g.\"cuda:1\"\n",
    "MODEL = 'UNetResNet34'#'RESNET34', 'RESNET18', 'INCEPTION_V3', 'BNINCEPTION', 'SEResnet50'\n",
    "#AUX_LOGITS = True#False, only for 'INCEPTION_V3'\n",
    "print('====MODEL ACHITECTURE: %s===='%MODEL)\n",
    "\n",
    "device = set_n_get_device(\"1, 2\", data_device_id=\"cuda:0\")#0, 1, 2, 3, IMPORTANT: data_device_id is set to free gpu for storing the model, e.g.\"cuda:1\"\n",
    "multi_gpu = [0, 1]#use 2 gpus\n",
    "\n",
    "SEED = 1234#5678#4567#3456#2345#1234\n",
    "debug = True# if True, load 100 samples\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 24\n",
    "warm_start, last_checkpoint_path = False, 'checkpoint/%s_%s_v1_seed%s/best.pth.tar'%(MODEL, IMG_SIZE, SEED)\n",
    "checkpoint_path = 'checkpoint/multitask_%s_%s_v1_seed%s'%(MODEL, IMG_SIZE, SEED)\n",
    "LOG_PATH = 'logging/multitask_%s_%s_v1_seed%s.log'%(MODEL, IMG_SIZE, SEED)#\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "NUM_EPOCHS = 100\n",
    "early_stopping_round = 10#500#50\n",
    "LearningRate = 0.02#phase1: 0.02, phase2: 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of trainset (for training):  900\n",
      "Count of validset (for training):  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "/home/bigdata/data/endi/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/bigdata/data/endi/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
      "[EPOCH 00000]train_loss_mask, train_loss_clf, train_metric: 0.07749, 0.66904, 0.70538; val_loss_mask, val_loss_clf, val_metric: 0.02297, 0.56849, 0.77083; time elapsed: 1.3 min\n",
      "[EPOCH 00001]train_loss_mask, train_loss_clf, train_metric: 0.01710, 0.53081, 0.79167; val_loss_mask, val_loss_clf, val_metric: 0.01845, 0.53771, 0.77083; time elapsed: 1.2 min\n",
      "[EPOCH 00002]train_loss_mask, train_loss_clf, train_metric: 0.01595, 0.51189, 0.79167; val_loss_mask, val_loss_clf, val_metric: 0.02012, 0.52884, 0.77083; time elapsed: 1.2 min\n",
      "[EPOCH 00003]train_loss_mask, train_loss_clf, train_metric: 0.01562, 0.50201, 0.79167; val_loss_mask, val_loss_clf, val_metric: 0.01434, 0.52588, 0.77083; time elapsed: 1.2 min\n",
      "[EPOCH 00004]train_loss_mask, train_loss_clf, train_metric: 0.01476, 0.49792, 0.79167; val_loss_mask, val_loss_clf, val_metric: 0.01485, 0.51645, 0.77083; time elapsed: 1.2 min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ec7bf772c8b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m######### Run the training process #########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrun_check_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-2506c2835fd0>\u001b[0m in \u001b[0;36mrun_check_net\u001b[0;34m(train_dl, val_dl, multi_gpu)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m#ia.imgaug.seed(i//10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mtruth_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;31m#define empty-mask as 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "######### Load data #########\n",
    "train_dl, val_dl = prepare_trainset(BATCH_SIZE, NUM_WORKERS, SEED, IMG_SIZE, debug)\n",
    "\n",
    "######### Run the training process #########\n",
    "run_check_net(train_dl, val_dl, multi_gpu=multi_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the validset, and analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import save_checkpoint, load_checkpoint, set_logger\n",
    "from gpu_utils import set_n_get_device\n",
    "\n",
    "from model.model_unet_deep_supervision import UNetResNet34, predict_proba\n",
    "from dataset_unet import prepare_trainset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====MODEL ACHITECTURE: UNetResNet34====\n"
     ]
    }
   ],
   "source": [
    "######### Config the training process #########\n",
    "#device = set_n_get_device(\"0, 1, 2, 3\", data_device_id=\"cuda:0\")#0, 1, 2, 3, IMPORTANT: data_device_id is set to free gpu for storing the model, e.g.\"cuda:1\"\n",
    "MODEL = 'UNetResNet34'#'RESNET34', 'RESNET18', 'INCEPTION_V3', 'BNINCEPTION', 'SEResnet50'\n",
    "#AUX_LOGITS = True#False, only for 'INCEPTION_V3'\n",
    "print('====MODEL ACHITECTURE: %s===='%MODEL)\n",
    "\n",
    "device = set_n_get_device(\"0\", data_device_id=\"cuda:0\")#0, 1, 2, 3, IMPORTANT: data_device_id is set to free gpu for storing the model, e.g.\"cuda:1\"\n",
    "multi_gpu = None#[0, 1]#use 2 gpus\n",
    "\n",
    "SEED = 3456#5678#4567#3456#2345#1234\n",
    "debug = False# if True, load 100 samples\n",
    "IMG_SIZE = 512\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of trainset (for training):  9607\n",
      "Count of validset (for training):  1068\n"
     ]
    }
   ],
   "source": [
    "train_dl, val_dl = prepare_trainset(BATCH_SIZE, NUM_WORKERS, SEED, IMG_SIZE, debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1064, 1, 512, 512), (1064, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y should be makeup\n",
    "valid_mask, valid_clf = [], []\n",
    "for i, (image, masks) in enumerate(val_dl):\n",
    "    truth_mask = masks#.to(device=device, dtype=torch.float)\n",
    "    truth_clf = (truth_mask.sum(dim=2).sum(dim=2)!=0).cpu().float().numpy()\n",
    "    valid_mask.append(truth_mask)\n",
    "    valid_clf.append(truth_clf)\n",
    "\n",
    "valid_mask = np.concatenate(valid_mask, axis=0)\n",
    "valid_clf = np.concatenate(valid_clf, axis=0)\n",
    "valid_mask.shape, valid_clf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNetResNet34(debug=False).cuda(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'checkpoint/deep_supervision_UNetResNet34_512_v1_seed3456/best.pth.tar'\n",
    "net, _ = load_checkpoint(checkpoint_path, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/data/endi/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/bigdata/data/endi/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 1s, sys: 2min 55s, total: 20min 56s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# predict_proba\n",
    "net.set_mode('valid')#.module\n",
    "pred = predict_proba(net, val_dl, device, multi_gpu=False, mode='valid', tta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1064, 512, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantile:  [0.75, 0.8, 0.8500000000000001, 0.9000000000000001, 0.9500000000000002]\n",
      "====================\n",
      "GT:  [   0.  466. 1159. 2346. 5201.]\n",
      "model:  [   0.    0.    0.  763. 2638.]\n"
     ]
    }
   ],
   "source": [
    "#s_val = valid_mask.reshape(valid_mask.shape[0], -1).sum(axis=1)\n",
    "#s_test = (sigmoid(preds_test)>MASK_THRESHOLD).astype(np.int).reshape(preds_test.shape[0], -1).sum(axis=1)\n",
    "\n",
    "quantiles = list(np.arange(0.75, 0.99, 0.05))\n",
    "print('quantile: ', quantiles)\n",
    "print('===='*5)\n",
    "print('GT: ', np.round(np.quantile(s_val, quantiles), 0))\n",
    "print('model: ', np.round(np.quantile(s_test, quantiles), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07894736842105263"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#s_val = (sigmoid(pred)>0.5).astype(np.int).reshape(pred.shape[0], -1).sum(axis=1)\n",
    "((s_val>0)*(s_val<1600)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## search for best thresholds\n",
    "def calculate_dice(logit, truth_mask, MASK_THRESHOLD=0.22, EMPTY_THRESHOLD=400):\n",
    "    IMG_SIZE = logit.shape[-1] #512\n",
    "    logit = sigmoid(logit)#.reshape(n, -1)\n",
    "    pred_mask = (logit>MASK_THRESHOLD).astype(np.int)\n",
    "    # clean mask if count(pixels)<EMPTY_THRESHOLD\n",
    "    pred_clf = (pred_mask.reshape(pred_mask.shape[0], -1).sum(axis=1)<EMPTY_THRESHOLD).astype(np.int)\n",
    "    pred_mask[pred_clf.reshape(-1,)==1, ] = 0\n",
    "    return dice_overall(pred_mask, truth_mask)\n",
    "\n",
    "def dice_overall(pred_mask, truth_mask, eps=1e-8):\n",
    "    n = pred_mask.shape[0]\n",
    "    pred_mask = pred_mask.reshape(n, -1)\n",
    "    truth_mask = truth_mask.reshape(n, -1)\n",
    "    intersect = (pred_mask * truth_mask).sum(axis=1).astype(np.float)\n",
    "    union = (pred_mask + truth_mask).sum(axis=1).astype(np.float)\n",
    "    return ((2.0*intersect + eps) / (union+eps)).mean()\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75178846ab7b46f3bd136a8df97c6da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMPTY_THRESHOLD: 1500.000000, MASK_THRESHOLD: 0.500000, dice_score: 0.828184\n",
      "EMPTY_THRESHOLD: 1600.000000, MASK_THRESHOLD: 0.500000, dice_score: 0.828184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#EMPTY_THRESHOLD_candidate = np.arange(1500, 1700, 100)#np.arange(350, 450, 10) for IMG_SIZE=256\n",
    "MASK_THRESHOLD_candidate = [0.5]#np.arange(0.40, 0.60, 0.02)\n",
    "#M, N = len(EMPTY_THRESHOLD_candidate), len(MASK_THRESHOLD_candidate)\n",
    "N = len(MASK_THRESHOLD_candidate)\n",
    "\n",
    "best_threshold = None\n",
    "best_score = 0\n",
    "\n",
    "# for i in tqdm_notebook(range(M)):\n",
    "#     EMPTY_THRESHOLD = EMPTY_THRESHOLD_candidate[i]\n",
    "#     for j in range(N):\n",
    "#         MASK_THRESHOLD = MASK_THRESHOLD_candidate[j]\n",
    "#         dice_score = calculate_dice(pred, valid_mask.squeeze(1), \n",
    "#                                     MASK_THRESHOLD, EMPTY_THRESHOLD)\n",
    "#         print('EMPTY_THRESHOLD: %f, MASK_THRESHOLD: %f, dice_score: %f'%(EMPTY_THRESHOLD, MASK_THRESHOLD, dice_score))\n",
    "#         if dice_score>best_score:\n",
    "#             best_threshold = [EMPTY_THRESHOLD, MASK_THRESHOLD]\n",
    "#             best_score = dice_score\n",
    "\n",
    "\n",
    "for j in tqdm_notebook(range(N)):\n",
    "    MASK_THRESHOLD = MASK_THRESHOLD_candidate[j]\n",
    "    dice_score = calculate_dice(pred, valid_mask.squeeze(1), \n",
    "                                MASK_THRESHOLD)\n",
    "    #print('EMPTY_THRESHOLD: %f, MASK_THRESHOLD: %f, dice_score: %f'%(EMPTY_THRESHOLD, MASK_THRESHOLD, dice_score))\n",
    "    print('MASK_THRESHOLD: %f, dice_score: %f'%(MASK_THRESHOLD, dice_score))\n",
    "    if dice_score>best_score:\n",
    "        #best_threshold = [EMPTY_THRESHOLD, MASK_THRESHOLD]\n",
    "        best_threshold = MASK_THRESHOLD\n",
    "        best_score = dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 0.5, 0.8281844382273233)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EMPTY_THRESHOLD, MASK_THRESHOLD = best_threshold\n",
    "# EMPTY_THRESHOLD, MASK_THRESHOLD, best_score\n",
    "\n",
    "MASK_THRESHOLD = best_threshold\n",
    "EMPTY_THRESHOLD = None\n",
    "EMPTY_THRESHOLD, MASK_THRESHOLD, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mask(logit, MASK_THRESHOLD, EMPTY_THRESHOLD=None):\n",
    "    \"\"\"Transform each prediction into mask.\n",
    "    input shape: (256, 256)\n",
    "    \"\"\"\n",
    "    #pred mask 0-1 pixel-wise\n",
    "    #n = logit.shape[0]\n",
    "    IMG_SIZE = logit.shape[-1] #256\n",
    "    #logit = torch.sigmoid(torch.from_numpy(logit)).view(n, -1)\n",
    "    #pred = (logit>MASK_THRESHOLD).long()\n",
    "    #pred[pred.sum(dim=1) < EMPTY_THRESHOLD, ] = 0 #bug here, found it, the bug is input shape is (256, 256) not (16,256,256)\n",
    "    \n",
    "    if EMPTY_THRESHOLD is None:\n",
    "        logit = sigmoid(logit)#.reshape(n, -1)\n",
    "        pred = (logit>MASK_THRESHOLD).astype(np.int)\n",
    "        return pred\n",
    "    else:\n",
    "        logit = sigmoid(logit)#.reshape(n, -1)\n",
    "        pred = (logit>MASK_THRESHOLD).astype(np.int)\n",
    "\n",
    "        if pred.sum() < EMPTY_THRESHOLD:\n",
    "            return np.zeros(pred.shape).astype(np.int)\n",
    "        else:\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## visualize predicted masks\n",
    "rows = 10\n",
    "\n",
    "cnt = 0\n",
    "for idx, (img, mask) in enumerate(val_dl):\n",
    "    for j in range(BATCH_SIZE):\n",
    "        not_empty = mask[j][0].sum()>0\n",
    "        if not_empty:\n",
    "            cnt+=1\n",
    "            pred_mask = predict_mask(pred[idx*BATCH_SIZE+j], MASK_THRESHOLD, EMPTY_THRESHOLD)\n",
    "#             pred_clf = sigmoid()\n",
    "#             if pred_clf>0.85:\n",
    "#                 pred_empty = True\n",
    "#             else:\n",
    "#                 pred_empty = False\n",
    "            #if pred_mask.sum()==0:\n",
    "            #    continue\n",
    "            fig, (ax0, ax1, ax2) = plt.subplots(ncols=3, figsize=(12, 4))\n",
    "            ax0.imshow(img[j][0].numpy(), plt.cm.bone)\n",
    "            ax1.imshow(mask[j][0], vmin=0, vmax=1, cmap=\"Reds\")\n",
    "            ax2.imshow(pred_mask, vmin=0, vmax=1, cmap=\"Blues\")\n",
    "            if not_empty.item():\n",
    "                ax1.set_title('Targets(Has Mask)')\n",
    "            else:\n",
    "                ax1.set_title('Targets(Empty)')\n",
    "            if pred_mask.sum()==0:#pred_empty:\n",
    "                ax2.set_title('Predict Empty')\n",
    "            else:\n",
    "                ax2.set_title('Predict Mask')\n",
    "            ax0.set_title('idx=%d'%(idx*16+j))\n",
    "        if cnt>rows:\n",
    "            break\n",
    "    if cnt>rows:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from metrics import dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8263)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice(torch.from_numpy(np.expand_dims(preds_valid, 1)), torch.from_numpy(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid.shape, preds_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8021)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice(torch.zeros(y_valid.shape), torch.from_numpy(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from dataset_unet import prepare_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1377, '1.2.276.0.7230010.3.1.4.8323329.6160.1517875196.806852')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fnames = [f.split('/')[-1][:-4] for f in glob.glob('data/processed/test/*')]\n",
    "len(test_fnames), test_fnames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = prepare_testset(BATCH_SIZE, NUM_WORKERS, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigdata/data/endi/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/bigdata/data/endi/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:2457: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 48s, sys: 4min 8s, total: 27min 56s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds_test = predict_proba(net, test_dl, device, multi_gpu=False, mode='test', tta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1377, 512, 512)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13217138707334786"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#s = (sigmoid(preds_test.reshape(preds_test.shape[0], -1))>0.6).astype(np.int).sum(axis=1)\n",
    "(s>0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## visualize predicted masks\n",
    "total = 19\n",
    "\n",
    "fig=plt.figure(figsize=(15, 20))\n",
    "cnt = 0\n",
    "for idx, img in enumerate(test_dl):\n",
    "    for j in range(BATCH_SIZE):#BATCH_SIZE\n",
    "        cnt+=1\n",
    "        pred_mask = predict_mask(preds_test[idx*BATCH_SIZE+j], MASK_THRESHOLD, EMPTY_THRESHOLD)\n",
    "        #if pred_mask.float().mean()==0:\n",
    "        #    continue\n",
    "        ax = fig.add_subplot(5, 4, cnt)\n",
    "        plt.imshow(img[j][0].numpy(), plt.cm.bone)\n",
    "        plt.imshow(pred_mask, alpha=0.3, cmap=\"Reds\")\n",
    "        if pred_mask.sum()>0:\n",
    "            plt.title('Predict Mask')\n",
    "        else:\n",
    "            plt.title('Predict Empty')\n",
    "        if cnt>total:\n",
    "            break\n",
    "    if cnt>total:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from mask_functions import mask2rle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1377, 512, 512)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694442f10dba4ba58d98bd00dfbf4610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1377), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1377\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6160.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.582.1517875163...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6985.151787520...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.5865.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6187.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ImageId EncodedPixels\n",
       "0  1.2.276.0.7230010.3.1.4.8323329.6160.151787519...            -1\n",
       "1  1.2.276.0.7230010.3.1.4.8323329.582.1517875163...            -1\n",
       "2  1.2.276.0.7230010.3.1.4.8323329.6985.151787520...            -1\n",
       "3  1.2.276.0.7230010.3.1.4.8323329.5865.151787519...            -1\n",
       "4  1.2.276.0.7230010.3.1.4.8323329.6187.151787519...            -1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Step 1: Generate rle encodings (images are first converted to the original size)\n",
    "rles = []\n",
    "for idx in tqdm_notebook(range(preds_test.shape[0])):#p is logit from model\n",
    "    pred_mask = preds_test[idx]\n",
    "    pred_mask = predict_mask(pred_mask, MASK_THRESHOLD, EMPTY_THRESHOLD)\n",
    "    if pred_mask.sum()>0:#predicted non-empty mask\n",
    "        im = PIL.Image.fromarray((pred_mask.T*255).astype(np.uint8)).resize((1024,1024))\n",
    "        im = np.asarray(im)\n",
    "        rles.append(mask2rle(im, 1024, 1024))\n",
    "    else: rles.append('-1')\n",
    "    \n",
    "sub_df = pd.DataFrame({'ImageId': test_fnames, 'EncodedPixels': rles})\n",
    "print(len(sub_df.index))\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the correctness of transformation before submit\n",
    "#i = 0\n",
    "i += 1\n",
    "pred_mask = predict_mask(preds_test[i], MASK_THRESHOLD, None)\n",
    "im = PIL.Image.fromarray((pred_mask.T*255).astype(np.uint8)).resize((1024,1024))\n",
    "im = np.asarray(im)\n",
    "im.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1df4c9d9b0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission/0723_deep_supervision_unet_512_v1_seed3456_.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Step 2: the sub is Instance Segmentation, so need to split mask into instances of masks\n",
    "def split_mask(mask):\n",
    "    MASK_THRESHOLD = 0.22\n",
    "    EMPTY_THRESHOLD = 30 #ignore predictions composed of 30 pixels or less\n",
    "    #split disconnected masks with ndimage.label function\n",
    "    labled,n_objs = ndimage.label(mask > MASK_THRESHOLD)\n",
    "    result = []\n",
    "    n_pixels = []\n",
    "    for i in range(n_objs):\n",
    "        obj = (labled == i + 1).astype(int)\n",
    "        if obj.sum() > EMPTY_THRESHOLD:\n",
    "            result.append(obj)\n",
    "            n_pixels.append(obj.sum())\n",
    "    #sort masks based on the number of pixels\n",
    "    result = [x for _,x in sorted(zip(n_pixels,result),reverse=True,key=lambda x:x[0])]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abb2b78c08f4e829008ba69e32418b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1377), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 3min 11s, sys: 3.99 s, total: 3min 15s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rles = []\n",
    "ids_c = []\n",
    "for p,idx in tqdm_notebook(zip(preds_test, test_fnames), total=len(preds_test)):\n",
    "    pred_mask = predict_mask(p)\n",
    "    if pred_mask.sum() > 0:\n",
    "        masks = split_mask(pred_mask)#to_np\n",
    "        for mask in masks:\n",
    "            ids_c.append(idx)\n",
    "            im = PIL.Image.fromarray((mask.T*255).astype(np.uint8)).resize((1024,1024))\n",
    "            im = np.asarray(im)\n",
    "            rles.append(mask2rle(im, 1024, 1024))\n",
    "        if len(masks) == 0:\n",
    "            rles.append('-1')\n",
    "            ids_c.append(idx)\n",
    "    else: \n",
    "        rles.append('-1')\n",
    "        ids_c.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1454\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6160.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.582.1517875163...</td>\n",
       "      <td>602280 20 1004 20 1004 20 1004 20 996 56 968 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.582.1517875163...</td>\n",
       "      <td>844468 8 1016 8 1016 8 1016 8 1016 8 1016 8 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.6985.151787520...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.276.0.7230010.3.1.4.8323329.5865.151787519...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ImageId  \\\n",
       "0  1.2.276.0.7230010.3.1.4.8323329.6160.151787519...   \n",
       "1  1.2.276.0.7230010.3.1.4.8323329.582.1517875163...   \n",
       "2  1.2.276.0.7230010.3.1.4.8323329.582.1517875163...   \n",
       "3  1.2.276.0.7230010.3.1.4.8323329.6985.151787520...   \n",
       "4  1.2.276.0.7230010.3.1.4.8323329.5865.151787519...   \n",
       "\n",
       "                                       EncodedPixels  \n",
       "0                                                 -1  \n",
       "1  602280 20 1004 20 1004 20 1004 20 996 56 968 5...  \n",
       "2  844468 8 1016 8 1016 8 1016 8 1016 8 1016 8 10...  \n",
       "3                                                 -1  \n",
       "4                                                 -1  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.DataFrame({'ImageId': ids_c, 'EncodedPixels': rles})\n",
    "print(len(sub_df))\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('submission/0708_unet_seed1234_split.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
